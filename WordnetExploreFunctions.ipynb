{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b20943db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "514b1228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/andrewcgaitskell/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0785f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The factorial of 3 is 6\n"
     ]
    }
   ],
   "source": [
    "def prev(x):\n",
    "    \"\"\"This is a recursive function\n",
    "    to find the factorial of an integer\"\"\"\n",
    "    \n",
    "    if x == 1:\n",
    "        return '1'\n",
    "    else:\n",
    "        return (x + prev(x-1))\n",
    "\n",
    "\n",
    "num = '3'\n",
    "print(\"The factorial of\", num, \"is\", prev(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de882f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog.n.01'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog')[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c78e7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = wn.synsets('dog')\n",
    "len(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f022fd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(root[0].lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "50f1c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x                  y\n"
     ]
    }
   ],
   "source": [
    "x4spaces = '    '\n",
    "x8spaces = 4 * x4spaces\n",
    "print('x',x8spaces,'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32dbaa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dog.n.01 n\n",
      "     dog\n",
      "         dog\n",
      "             dog\n",
      "             domestic_dog\n",
      "             Canis_familiaris\n",
      "         frump\n",
      "             frump\n",
      "             dog\n",
      "         dog\n",
      "             dog\n",
      "         cad\n",
      "             cad\n",
      "             bounder\n",
      "             blackguard\n",
      "             dog\n",
      "             hound\n",
      "             heel\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "         pawl\n",
      "             pawl\n",
      "             detent\n",
      "             click\n",
      "             dog\n",
      "         andiron\n",
      "             andiron\n",
      "             firedog\n",
      "             dog\n",
      "             dog-iron\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "     domestic_dog\n",
      "         dog\n",
      "             dog\n",
      "             domestic_dog\n",
      "             Canis_familiaris\n",
      "     Canis_familiaris\n",
      "         dog\n",
      "             dog\n",
      "             domestic_dog\n",
      "             Canis_familiaris\n",
      "1 frump.n.01 n\n",
      "     frump\n",
      "         frump\n",
      "             frump\n",
      "             dog\n",
      "     dog\n",
      "         dog\n",
      "             dog\n",
      "             domestic_dog\n",
      "             Canis_familiaris\n",
      "         frump\n",
      "             frump\n",
      "             dog\n",
      "         dog\n",
      "             dog\n",
      "         cad\n",
      "             cad\n",
      "             bounder\n",
      "             blackguard\n",
      "             dog\n",
      "             hound\n",
      "             heel\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "         pawl\n",
      "             pawl\n",
      "             detent\n",
      "             click\n",
      "             dog\n",
      "         andiron\n",
      "             andiron\n",
      "             firedog\n",
      "             dog\n",
      "             dog-iron\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "2 dog.n.03 n\n",
      "     dog\n",
      "         dog\n",
      "             dog\n",
      "             domestic_dog\n",
      "             Canis_familiaris\n",
      "         frump\n",
      "             frump\n",
      "             dog\n",
      "         dog\n",
      "             dog\n",
      "         cad\n",
      "             cad\n",
      "             bounder\n",
      "             blackguard\n",
      "             dog\n",
      "             hound\n",
      "             heel\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "         pawl\n",
      "             pawl\n",
      "             detent\n",
      "             click\n",
      "             dog\n",
      "         andiron\n",
      "             andiron\n",
      "             firedog\n",
      "             dog\n",
      "             dog-iron\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "3 cad.n.01 n\n",
      "     cad\n",
      "         cad\n",
      "             cad\n",
      "             bounder\n",
      "             blackguard\n",
      "             dog\n",
      "             hound\n",
      "             heel\n",
      "         computer-aided_design\n",
      "             computer-aided_design\n",
      "             CAD\n",
      "     bounder\n",
      "         cad\n",
      "             cad\n",
      "             bounder\n",
      "             blackguard\n",
      "             dog\n",
      "             hound\n",
      "             heel\n",
      "         bounder\n",
      "             bounder\n",
      "             leaper\n",
      "     blackguard\n",
      "         cad\n",
      "             cad\n",
      "             bounder\n",
      "             blackguard\n",
      "             dog\n",
      "             hound\n",
      "             heel\n",
      "         ridicule\n",
      "             ridicule\n",
      "             roast\n",
      "             guy\n",
      "             blackguard\n",
      "             laugh_at\n",
      "             jest_at\n",
      "             rib\n",
      "             make_fun\n",
      "             poke_fun\n",
      "         abuse\n",
      "             abuse\n",
      "             clapperclaw\n",
      "             blackguard\n",
      "             shout\n",
      "     dog\n",
      "         dog\n",
      "             dog\n",
      "             domestic_dog\n",
      "             Canis_familiaris\n",
      "         frump\n",
      "             frump\n",
      "             dog\n",
      "         dog\n",
      "             dog\n",
      "         cad\n",
      "             cad\n",
      "             bounder\n",
      "             blackguard\n",
      "             dog\n",
      "             hound\n",
      "             heel\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "         pawl\n",
      "             pawl\n",
      "             detent\n",
      "             click\n",
      "             dog\n",
      "         andiron\n",
      "             andiron\n",
      "             firedog\n",
      "             dog\n",
      "             dog-iron\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "     hound\n",
      "         hound\n",
      "             hound\n",
      "             hound_dog\n",
      "         cad\n",
      "             cad\n",
      "             bounder\n",
      "             blackguard\n",
      "             dog\n",
      "             hound\n",
      "             heel\n",
      "         hound\n",
      "             hound\n",
      "             hunt\n",
      "             trace\n",
      "     heel\n",
      "         heel\n",
      "             heel\n",
      "         heel\n",
      "             heel\n",
      "         cad\n",
      "             cad\n",
      "             bounder\n",
      "             blackguard\n",
      "             dog\n",
      "             hound\n",
      "             heel\n",
      "         heel\n",
      "             heel\n",
      "         heel\n",
      "             heel\n",
      "         heel\n",
      "             heel\n",
      "         list\n",
      "             list\n",
      "             heel\n",
      "         heel\n",
      "             heel\n",
      "         heel\n",
      "             heel\n",
      "         heel\n",
      "             heel\n",
      "         heel\n",
      "             heel\n",
      "             reheel\n",
      "4 frank.n.02 n\n",
      "     frank\n",
      "         Frank\n",
      "             Frank\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "         postmark\n",
      "             postmark\n",
      "             frank\n",
      "         frank\n",
      "             frank\n",
      "         blunt\n",
      "             blunt\n",
      "             candid\n",
      "             forthright\n",
      "             frank\n",
      "             free-spoken\n",
      "             outspoken\n",
      "             plainspoken\n",
      "             point-blank\n",
      "             straight-from-the-shoulder\n",
      "         frank\n",
      "             frank\n",
      "     frankfurter\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "     hotdog\n",
      "         hotdog\n",
      "             hotdog\n",
      "             hot_dog\n",
      "         hotdog\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             red_hot\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "     hot_dog\n",
      "         hotdog\n",
      "             hotdog\n",
      "             hot_dog\n",
      "         hotdog\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             red_hot\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "     dog\n",
      "         dog\n",
      "             dog\n",
      "             domestic_dog\n",
      "             Canis_familiaris\n",
      "         frump\n",
      "             frump\n",
      "             dog\n",
      "         dog\n",
      "             dog\n",
      "         cad\n",
      "             cad\n",
      "             bounder\n",
      "             blackguard\n",
      "             dog\n",
      "             hound\n",
      "             heel\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "         pawl\n",
      "             pawl\n",
      "             detent\n",
      "             click\n",
      "             dog\n",
      "         andiron\n",
      "             andiron\n",
      "             firedog\n",
      "             dog\n",
      "             dog-iron\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "     wiener\n",
      "         Wiener\n",
      "             Wiener\n",
      "             Norbert_Wiener\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "     wienerwurst\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "     weenie\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "5 pawl.n.01 n\n",
      "     pawl\n",
      "         pawl\n",
      "             pawl\n",
      "             detent\n",
      "             click\n",
      "             dog\n",
      "     detent\n",
      "         pawl\n",
      "             pawl\n",
      "             detent\n",
      "             click\n",
      "             dog\n",
      "     click\n",
      "         chink\n",
      "             chink\n",
      "             click\n",
      "             clink\n",
      "         suction_stop\n",
      "             suction_stop\n",
      "             click\n",
      "         pawl\n",
      "             pawl\n",
      "             detent\n",
      "             click\n",
      "             dog\n",
      "         click\n",
      "             click\n",
      "             mouse_click\n",
      "         snap\n",
      "             snap\n",
      "             click\n",
      "         click\n",
      "             click\n",
      "             tick\n",
      "         chatter\n",
      "             chatter\n",
      "             click\n",
      "         snap\n",
      "             snap\n",
      "             click\n",
      "             flick\n",
      "         click\n",
      "             click\n",
      "         cluck\n",
      "             cluck\n",
      "             click\n",
      "             clack\n",
      "         click\n",
      "             click\n",
      "             get_through\n",
      "             dawn\n",
      "             come_home\n",
      "             get_across\n",
      "             sink_in\n",
      "             penetrate\n",
      "             fall_into_place\n",
      "     dog\n",
      "         dog\n",
      "             dog\n",
      "             domestic_dog\n",
      "             Canis_familiaris\n",
      "         frump\n",
      "             frump\n",
      "             dog\n",
      "         dog\n",
      "             dog\n",
      "         cad\n",
      "             cad\n",
      "             bounder\n",
      "             blackguard\n",
      "             dog\n",
      "             hound\n",
      "             heel\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "         pawl\n",
      "             pawl\n",
      "             detent\n",
      "             click\n",
      "             dog\n",
      "         andiron\n",
      "             andiron\n",
      "             firedog\n",
      "             dog\n",
      "             dog-iron\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "6 andiron.n.01 n\n",
      "     andiron\n",
      "         andiron\n",
      "             andiron\n",
      "             firedog\n",
      "             dog\n",
      "             dog-iron\n",
      "     firedog\n",
      "         andiron\n",
      "             andiron\n",
      "             firedog\n",
      "             dog\n",
      "             dog-iron\n",
      "     dog\n",
      "         dog\n",
      "             dog\n",
      "             domestic_dog\n",
      "             Canis_familiaris\n",
      "         frump\n",
      "             frump\n",
      "             dog\n",
      "         dog\n",
      "             dog\n",
      "         cad\n",
      "             cad\n",
      "             bounder\n",
      "             blackguard\n",
      "             dog\n",
      "             hound\n",
      "             heel\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "         pawl\n",
      "             pawl\n",
      "             detent\n",
      "             click\n",
      "             dog\n",
      "         andiron\n",
      "             andiron\n",
      "             firedog\n",
      "             dog\n",
      "             dog-iron\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "     dog-iron\n",
      "         andiron\n",
      "             andiron\n",
      "             firedog\n",
      "             dog\n",
      "             dog-iron\n",
      "7 chase.v.01 v\n",
      "     chase\n",
      "         pursuit\n",
      "             pursuit\n",
      "             chase\n",
      "             pursual\n",
      "             following\n",
      "         Chase\n",
      "             Chase\n",
      "             Salmon_P._Chase\n",
      "             Salmon_Portland_Chase\n",
      "         chase\n",
      "             chase\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "         chase\n",
      "             chase\n",
      "         furrow\n",
      "             furrow\n",
      "             chamfer\n",
      "             chase\n",
      "     chase_after\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "     trail\n",
      "         trail\n",
      "             trail\n",
      "         trail\n",
      "             trail\n",
      "         lead\n",
      "             lead\n",
      "             track\n",
      "             trail\n",
      "         drag\n",
      "             drag\n",
      "             trail\n",
      "             get_behind\n",
      "             hang_back\n",
      "             drop_behind\n",
      "             drop_back\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "         trail\n",
      "             trail\n",
      "             shack\n",
      "         trail\n",
      "             trail\n",
      "         trail\n",
      "             trail\n",
      "             train\n",
      "     tail\n",
      "         tail\n",
      "             tail\n",
      "         fag_end\n",
      "             fag_end\n",
      "             tail\n",
      "             tail_end\n",
      "         tail\n",
      "             tail\n",
      "             tail_end\n",
      "         buttocks\n",
      "             buttocks\n",
      "             nates\n",
      "             arse\n",
      "             butt\n",
      "             backside\n",
      "             bum\n",
      "             buns\n",
      "             can\n",
      "             fundament\n",
      "             hindquarters\n",
      "             hind_end\n",
      "             keister\n",
      "             posterior\n",
      "             prat\n",
      "             rear\n",
      "             rear_end\n",
      "             rump\n",
      "             stern\n",
      "             seat\n",
      "             tail\n",
      "             tail_end\n",
      "             tooshie\n",
      "             tush\n",
      "             bottom\n",
      "             behind\n",
      "             derriere\n",
      "             fanny\n",
      "             ass\n",
      "         tail\n",
      "             tail\n",
      "             shadow\n",
      "             shadower\n",
      "         tail\n",
      "             tail\n",
      "         tail\n",
      "             tail\n",
      "             tail_assembly\n",
      "             empennage\n",
      "         stern\n",
      "             stern\n",
      "             after_part\n",
      "             quarter\n",
      "             poop\n",
      "             tail\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "         dock\n",
      "             dock\n",
      "             tail\n",
      "             bob\n",
      "         tail\n",
      "             tail\n",
      "     tag\n",
      "         tag\n",
      "             tag\n",
      "             ticket\n",
      "         tag\n",
      "             tag\n",
      "         rag\n",
      "             rag\n",
      "             shred\n",
      "             tag\n",
      "             tag_end\n",
      "             tatter\n",
      "         tag\n",
      "             tag\n",
      "         tag\n",
      "             tag\n",
      "         tag\n",
      "             tag\n",
      "             label\n",
      "             mark\n",
      "         tag\n",
      "             tag\n",
      "         tag\n",
      "             tag\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "         tag\n",
      "             tag\n",
      "     give_chase\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "     dog\n",
      "         dog\n",
      "             dog\n",
      "             domestic_dog\n",
      "             Canis_familiaris\n",
      "         frump\n",
      "             frump\n",
      "             dog\n",
      "         dog\n",
      "             dog\n",
      "         cad\n",
      "             cad\n",
      "             bounder\n",
      "             blackguard\n",
      "             dog\n",
      "             hound\n",
      "             heel\n",
      "         frank\n",
      "             frank\n",
      "             frankfurter\n",
      "             hotdog\n",
      "             hot_dog\n",
      "             dog\n",
      "             wiener\n",
      "             wienerwurst\n",
      "             weenie\n",
      "         pawl\n",
      "             pawl\n",
      "             detent\n",
      "             click\n",
      "             dog\n",
      "         andiron\n",
      "             andiron\n",
      "             firedog\n",
      "             dog\n",
      "             dog-iron\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "     go_after\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "         quest_for\n",
      "             quest_for\n",
      "             go_after\n",
      "             quest_after\n",
      "             pursue\n",
      "     track\n",
      "         path\n",
      "             path\n",
      "             track\n",
      "             course\n",
      "         lead\n",
      "             lead\n",
      "             track\n",
      "             trail\n",
      "         track\n",
      "             track\n",
      "         racetrack\n",
      "             racetrack\n",
      "             racecourse\n",
      "             raceway\n",
      "             track\n",
      "         cut\n",
      "             cut\n",
      "             track\n",
      "         track\n",
      "             track\n",
      "             caterpillar_track\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             caterpillar_tread\n",
      "         track\n",
      "             track\n",
      "             data_track\n",
      "         track\n",
      "             track\n",
      "         track\n",
      "             track\n",
      "             rail\n",
      "             rails\n",
      "             runway\n",
      "         track\n",
      "             track\n",
      "             cart_track\n",
      "             cartroad\n",
      "         track\n",
      "             track\n",
      "             running\n",
      "         track\n",
      "             track\n",
      "         track\n",
      "             track\n",
      "         chase\n",
      "             chase\n",
      "             chase_after\n",
      "             trail\n",
      "             tail\n",
      "             tag\n",
      "             give_chase\n",
      "             dog\n",
      "             go_after\n",
      "             track\n",
      "         traverse\n",
      "             traverse\n",
      "             track\n",
      "             cover\n",
      "             cross\n",
      "             pass_over\n",
      "             get_over\n",
      "             get_across\n",
      "             cut_through\n",
      "             cut_across\n",
      "         track\n",
      "             track\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(root)):\n",
    "    print(i, root[i].name(), root[i].pos())\n",
    "    try:\n",
    "        for j in range(0,len(root[i].lemmas())):\n",
    "            print(x4spaces, root[i].lemmas()[j].name())\n",
    "            lemma_name = root[i].lemmas()[j].name()\n",
    "            synets_level1 = wn.synsets(lemma_name)\n",
    "            for k in range(0,len(synets_level1)):\n",
    "                #print('     ',synets_level1[k].name())\n",
    "                print(x4spaces*2, synets_level1[k].lemmas()[0].name())\n",
    "                for l in range(0,len(synets_level1[k].lemmas())):\n",
    "                    print(x4spaces*3, synets_level1[k].lemmas()[l].name())\n",
    "                #print(k)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06471cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chase.v.01')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog', pos=wn.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511a37e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('dog.n.01').definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9414474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dog barked all night\n"
     ]
    }
   ],
   "source": [
    "len(wn.synset('dog.n.01').examples())\n",
    "print(wn.synset('dog.n.01').examples()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c8eb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('dog.n.01.dog'),\n",
       " Lemma('dog.n.01.domestic_dog'),\n",
       " Lemma('dog.n.01.Canis_familiaris')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('dog.n.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "838b15a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'domestic_dog', 'Canis_familiaris']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(lemma.name()) for lemma in wn.synset('dog.n.01').lemmas()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd0ef8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('dog.n.01')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('dog.n.01.dog').synset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c09732",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Synsets\n",
    "\n",
    "#Synset: a set of synonyms that share a common meaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea6f69da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = wn.synset('dog.n.01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48b5f5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypernyms [Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n"
     ]
    }
   ],
   "source": [
    "print('hypernyms' ,dog.hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fba20c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('carnivore.n.01')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "##[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
    "dog.hyponyms()\n",
    "##[Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'), Synset('dalmatian.n.02'), ...]\n",
    "dog.member_holonyms()\n",
    "##[Synset('canis.n.01'), Synset('pack.n.06')]\n",
    "dog.root_hypernyms()\n",
    "##[Synset('entity.n.01')]\n",
    "wn.synset('dog.n.01').lowest_common_hypernyms(wn.synset('cat.n.01'))\n",
    "##[Synset('carnivore.n.01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4033f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('carnivore.n.01')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.lowest_common_hypernyms(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f98051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "053a2aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('bad.a.01.bad')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Each synset contains one or more lemmas, which represent a specific sense of a specific word.\n",
    "\n",
    "#Note that some relations are defined by WordNet only over Lemmas:\n",
    "\n",
    "good = wn.synset('good.a.01')\n",
    "#good.antonyms()\n",
    "#Traceback (most recent call last):\n",
    "#  File \"<stdin>\", line 1, in <module>\n",
    "#AttributeError: 'Synset' object has no attribute 'antonyms'\n",
    "good.lemmas()[0].antonyms()\n",
    "#[Lemma('bad.a.01.bad')]\n",
    "\n",
    "#The relations that are currently defined in this way are antonyms, derivationally_related_forms and pertainyms.\n",
    "\n",
    "#If you know the byte offset used to identify a synset in the original Princeton WordNet data file, you can use that to instantiate the synset in NLTK:\n",
    "\n",
    "#>>> wn.synset_from_pos_and_offset('n', 4543158)\n",
    "#Synset('wagon.n.01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc38963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat%2:34:02::\n",
      "Lemma('feed.v.06.feed') 3\n",
      "Lemma('feed.v.06.eat') 4\n",
      "Lemma('eat.v.01.eat') 61\n",
      "Lemma('eat.v.02.eat') 13\n",
      "Lemma('feed.v.06.eat') 4\n",
      "Lemma('eat.v.04.eat') 0\n",
      "Lemma('consume.v.05.eat') 0\n",
      "Lemma('corrode.v.01.eat') 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lemma('jump.v.11.jump')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmas\n",
    "\n",
    "eat = wn.lemma('eat.v.03.eat')\n",
    "eat\n",
    "#Lemma('feed.v.06.eat')\n",
    "print(eat.key())\n",
    "#eat%2:34:02::\n",
    "eat.count()\n",
    "#4\n",
    "wn.lemma_from_key(eat.key())\n",
    "#Lemma('feed.v.06.eat')\n",
    "wn.lemma_from_key(eat.key()).synset()\n",
    "#Synset('feed.v.06')\n",
    "wn.lemma_from_key('feebleminded%5:00:00:retarded:00')\n",
    "#Lemma('backward.s.03.feebleminded')\n",
    "for lemma in wn.synset('eat.v.03').lemmas():\n",
    "    print(lemma, lemma.count())\n",
    "#...\n",
    "#Lemma('feed.v.06.feed') 3\n",
    "#Lemma('feed.v.06.eat') 4\n",
    "for lemma in wn.lemmas('eat', 'v'):\n",
    "    print(lemma, lemma.count())\n",
    "\n",
    "#Lemma('eat.v.01.eat') 61\n",
    "#Lemma('eat.v.02.eat') 13\n",
    "#Lemma('feed.v.06.eat') 4\n",
    "#Lemma('eat.v.04.eat') 0\n",
    "#Lemma('consume.v.05.eat') 0\n",
    "#Lemma('corrode.v.01.eat') 0\n",
    "wn.lemma('jump.v.11.jump')\n",
    "#Lemma('jump.v.11.jump')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5baaba50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('instrumental.a.01.instrumental')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmas can also have relations between them:\n",
    "\n",
    "vocal = wn.lemma('vocal.a.01.vocal')\n",
    "vocal.derivationally_related_forms()\n",
    "#[Lemma('vocalize.v.02.vocalize')]\n",
    "vocal.pertainyms()\n",
    "#[Lemma('voice.n.02.voice')]\n",
    "vocal.antonyms()\n",
    "#[Lemma('instrumental.a.01.instrumental')]\n",
    "\n",
    "#The three relations above exist only on lemmas, not on synsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e29c4ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Similarity\n",
    "\n",
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "\n",
    "hit = wn.synset('hit.v.01')\n",
    "slap = wn.synset('slap.v.01')\n",
    "\n",
    "#synset1.path_similarity(synset2):\n",
    "#Return a score denoting how similar two word senses are, based on the shortest path\n",
    "##that connects the senses in the is-a (hypernym/hypnoym) taxonomy.\n",
    "##The score is in the range 0 to 1. By default, there is now a fake root node added to verbs\n",
    "##so for cases where previously a path could not be found—and None\n",
    "##was returned—it should return a value. The old behavior can be achieved by\n",
    "##setting simulate_root to be False. A score of 1 represents identity i.e. comparing a sense\n",
    "##with itself will return 1.\n",
    "\n",
    "dog.path_similarity(cat)\n",
    "#0.2...\n",
    "\n",
    "hit.path_similarity(slap)\n",
    "#0.142...\n",
    "\n",
    "wn.path_similarity(hit, slap)\n",
    "#0.142...\n",
    "\n",
    "print(hit.path_similarity(slap, simulate_root=False))\n",
    "#None\n",
    "\n",
    "print(wn.path_similarity(hit, slap, simulate_root=False))\n",
    "#None\n",
    "\n",
    "##synset1.lch_similarity(synset2):\n",
    "##Leacock-Chodorow Similarity: Return a score denoting how similar two word senses are,\n",
    "##based on the shortest path that connects the senses (as above) and the maximum depth\n",
    "##of the taxonomy in which the senses occur. The relationship is given as -log(p/2d)\n",
    "##where p is the shortest path length and d the taxonomy depth.\n",
    "\n",
    "dog.lch_similarity(cat)\n",
    "##2.028...\n",
    "\n",
    "hit.lch_similarity(slap)\n",
    "##1.312...\n",
    "\n",
    "wn.lch_similarity(hit, slap)\n",
    "#1.312...\n",
    "\n",
    "print(hit.lch_similarity(slap, simulate_root=False))\n",
    "##None\n",
    "\n",
    "print(wn.lch_similarity(hit, slap, simulate_root=False))\n",
    "#None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69bb4e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''synset1.wup_similarity(synset2):\n",
    "Wu-Palmer Similarity: Return a score denoting how similar two word senses are,\n",
    "    based on the depth of the two senses in the taxonomy and that of their\n",
    "    Least Common Subsumer (most specific ancestor node). Note that at this\n",
    "    time the scores given do _not_ always agree with those given by\n",
    "    Pedersen’s Perl implementation of Wordnet Similarity.\n",
    "'''\n",
    "\n",
    "'''\n",
    "The LCS does not necessarily feature in the shortest path connecting the two senses,\n",
    "as it is by definition the common ancestor deepest in the taxonomy,\n",
    "not closest to the two senses. Typically, however, it will so feature.\n",
    "Where multiple candidates for the LCS exist, that whose shortest path to\n",
    "the root node is the longest will be selected.\n",
    "Where the LCS has multiple paths to the root, the longer path is used\n",
    "for the purposes of the calculation.\n",
    "'''\n",
    "\n",
    "dog.wup_similarity(cat,verbose=True)\n",
    "##0.857...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96fb7f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "hit.wup_similarity(slap)\n",
    "##0.25\n",
    "\n",
    "wn.wup_similarity(hit, slap)\n",
    "##0.25\n",
    "\n",
    "print(hit.wup_similarity(slap, simulate_root=False))\n",
    "##None\n",
    "\n",
    "print(wn.wup_similarity(hit, slap, simulate_root=False))\n",
    "##None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "517264f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('entity.n.01')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('abstraction.n.06')\n",
      "Synset('thing.n.12')\n",
      "Synset('object.n.01')\n",
      "Synset('whole.n.02')\n",
      "Synset('congener.n.03')\n",
      "Synset('living_thing.n.01')\n",
      "Synset('organism.n.01')\n",
      "Synset('benthos.n.02')\n",
      "Synset('entity.n.01') []\n",
      "Synset('physical_entity.n.01') [Synset('entity.n.01')]\n",
      "Synset('abstraction.n.06') [Synset('entity.n.01')]\n",
      "Synset('thing.n.12') [Synset('physical_entity.n.01')]\n",
      "Synset('object.n.01') [Synset('physical_entity.n.01')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Access to all Synsets\n",
    "\n",
    "#Iterate over all the noun synsets:\n",
    "\n",
    "for synset in list(wn.all_synsets('n'))[:10]:\n",
    "    print(synset)\n",
    "\n",
    "#Synset('entity.n.01')\n",
    "#Synset('physical_entity.n.01')\n",
    "#Synset('abstraction.n.06')\n",
    "#Synset('thing.n.12')\n",
    "#Synset('object.n.01')\n",
    "#Synset('whole.n.02')\n",
    "#Synset('congener.n.03')\n",
    "#Synset('living_thing.n.01')\n",
    "#Synset('organism.n.01')\n",
    "#Synset('benthos.n.02')\n",
    "\n",
    "#Get all synsets for this word, possibly restricted by POS:\n",
    "\n",
    "wn.synsets('dog')\n",
    "#[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), ...]\n",
    "wn.synsets('dog', pos='v')\n",
    "#[Synset('chase.v.01')]\n",
    "\n",
    "#Walk through the noun synsets looking at their hypernyms:\n",
    "\n",
    "from itertools import islice\n",
    "for synset in islice(wn.all_synsets('n'), 5):\n",
    "    print(synset, synset.hypernyms())\n",
    "\n",
    "#Synset('entity.n.01') []\n",
    "#Synset('physical_entity.n.01') [Synset('entity.n.01')]\n",
    "#Synset('abstraction.n.06') [Synset('entity.n.01')]\n",
    "#Synset('thing.n.12') [Synset('physical_entity.n.01')]\n",
    "#Synset('object.n.01') [Synset('physical_entity.n.01')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40a7f336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('slang.n.02')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('code.n.03').topic_domains()\n",
    "#[Synset('computer_science.n.01')]\n",
    "wn.synset('pukka.a.01').region_domains()\n",
    "##[Synset('india.n.01')]\n",
    "wn.synset('freaky.a.01').usage_domains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f731e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('bound.a.01'),\n",
      " [Synset('unfree.a.02'),\n",
      "  [Synset('confined.a.02'),\n",
      "   [Synset('restricted.a.01'), [Synset('classified.a.02')]]],\n",
      "  [Synset('dependent.a.01')],\n",
      "  [Synset('restricted.a.01'),\n",
      "   [Synset('classified.a.02')],\n",
      "   [Synset('confined.a.02')]]]]\n",
      "[Synset('bound.a.01'),\n",
      " [Synset('unfree.a.02'),\n",
      "  \"Cycle(Synset('bound.a.01'),-3,...)\",\n",
      "  [Synset('confined.a.02'),\n",
      "   [Synset('restricted.a.01'),\n",
      "    [Synset('classified.a.02')],\n",
      "    \"Cycle(Synset('confined.a.02'),-5,...)\",\n",
      "    \"Cycle(Synset('unfree.a.02'),-5,...)\"],\n",
      "   \"Cycle(Synset('unfree.a.02'),-4,...)\"],\n",
      "  [Synset('dependent.a.01'), \"Cycle(Synset('unfree.a.02'),-4,...)\"],\n",
      "  [Synset('restricted.a.01'),\n",
      "   [Synset('classified.a.02')],\n",
      "   [Synset('confined.a.02'),\n",
      "    \"Cycle(Synset('restricted.a.01'),-5,...)\",\n",
      "    \"Cycle(Synset('unfree.a.02'),-5,...)\"],\n",
      "   \"Cycle(Synset('unfree.a.02'),-4,...)\"]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrewcgaitskell/.local/share/virtualenvs/JokeIdeaGenerator-fEmoDMJg/lib/python3.8/site-packages/nltk/corpus/reader/wordnet.py:634: UserWarning: Discarded redundant search for Synset('bound.a.01') at depth -3\n",
      "  return acyclic_branches_depth_first(self, rel, depth, cut_mark)\n",
      "/home/andrewcgaitskell/.local/share/virtualenvs/JokeIdeaGenerator-fEmoDMJg/lib/python3.8/site-packages/nltk/util.py:488: UserWarning: Discarded redundant search for Synset('confined.a.02') at depth -5\n",
      "  acyclic_branches_depth_first(\n",
      "/home/andrewcgaitskell/.local/share/virtualenvs/JokeIdeaGenerator-fEmoDMJg/lib/python3.8/site-packages/nltk/util.py:488: UserWarning: Discarded redundant search for Synset('unfree.a.02') at depth -5\n",
      "  acyclic_branches_depth_first(\n",
      "/home/andrewcgaitskell/.local/share/virtualenvs/JokeIdeaGenerator-fEmoDMJg/lib/python3.8/site-packages/nltk/util.py:488: UserWarning: Discarded redundant search for Synset('unfree.a.02') at depth -4\n",
      "  acyclic_branches_depth_first(\n",
      "/home/andrewcgaitskell/.local/share/virtualenvs/JokeIdeaGenerator-fEmoDMJg/lib/python3.8/site-packages/nltk/util.py:488: UserWarning: Discarded redundant search for Synset('restricted.a.01') at depth -5\n",
      "  acyclic_branches_depth_first(\n"
     ]
    }
   ],
   "source": [
    "#Endlessness vs. intractability in relation trees\n",
    "##1. Endlessness\n",
    "\n",
    "'''Until NLTK v. 3.5, the tree() function looped forever on symmetric relations \n",
    "(verb_groups, attributes, and most also_sees). But in the current version, tree()\n",
    "now detects and discards these cycles:\n",
    "'''\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(wn.synset('bound.a.01').tree(lambda s:s.also_sees()))\n",
    "#[Synset('bound.a.01'),\n",
    "# [Synset('unfree.a.02'),\n",
    "#  [Synset('confined.a.02'),\n",
    "#   [Synset('restricted.a.01'), [Synset('classified.a.02')]]],\n",
    "#  [Synset('dependent.a.01')],\n",
    "#  [Synset('restricted.a.01'),\n",
    "#   [Synset('classified.a.02')],\n",
    "#   [Synset('confined.a.02')]]]]\n",
    "\n",
    "#Specifying the “cut_mark” parameter increases verbosity,\n",
    "#so that the cycles are mentioned in the output,\n",
    "#together with the level where they occur:\n",
    "\n",
    "pprint(wn.synset('bound.a.01').tree(lambda s:s.also_sees(),cut_mark='...'))\n",
    "#[Synset('bound.a.01'),\n",
    "# [Synset('unfree.a.02'),\n",
    "#  \"Cycle(Synset('bound.a.01'),-3,...)\",\n",
    "#  [Synset('confined.a.02'),\n",
    "#   [Synset('restricted.a.01'),\n",
    "#    [Synset('classified.a.02')],\n",
    "#    \"Cycle(Synset('confined.a.02'),-5,...)\",\n",
    "#    \"Cycle(Synset('unfree.a.02'),-5,...)\"],\n",
    "#   \"Cycle(Synset('unfree.a.02'),-4,...)\"],\n",
    "#  [Synset('dependent.a.01'), \"Cycle(Synset('unfree.a.02'),-4,...)\"],\n",
    "#  [Synset('restricted.a.01'),\n",
    "#   [Synset('classified.a.02')],\n",
    "#   [Synset('confined.a.02'),\n",
    "#    \"Cycle(Synset('restricted.a.01'),-5,...)\",\n",
    "#    \"Cycle(Synset('unfree.a.02'),-5,...)\"],\n",
    "#   \"Cycle(Synset('unfree.a.02'),-4,...)\"]]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2ac05d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('concrete.a.01'),\n",
      " [Synset('practical.a.01'),\n",
      "  \"Cycle(Synset('concrete.a.01'),0,...)\",\n",
      "  [Synset('possible.a.01'), '...'],\n",
      "  [Synset('realistic.a.01'), '...'],\n",
      "  [Synset('serviceable.a.01'), '...']],\n",
      " [Synset('real.a.01'),\n",
      "  \"Cycle(Synset('concrete.a.01'),0,...)\",\n",
      "  [Synset('genuine.a.01'), '...'],\n",
      "  [Synset('realistic.a.01'), '...'],\n",
      "  [Synset('sincere.a.01'), '...']],\n",
      " [Synset('tangible.a.01'), \"Cycle(Synset('concrete.a.01'),0,...)\"]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrewcgaitskell/.local/share/virtualenvs/JokeIdeaGenerator-fEmoDMJg/lib/python3.8/site-packages/nltk/corpus/reader/wordnet.py:634: UserWarning: Discarded redundant search for Synset('concrete.a.01') at depth 0\n",
      "  return acyclic_branches_depth_first(self, rel, depth, cut_mark)\n"
     ]
    }
   ],
   "source": [
    "#2. Intractability\n",
    "\n",
    "#However, even after discarding the infinite cycles, some trees can remain intractable,\n",
    "#due to combinatorial explosion in a relation. This happens in WordNet, because the also.sees()\n",
    "##relation has a big Strongly Connected Component (_SCC_) consisting in 758 synsets,\n",
    "#where any member node is transitively connected by the same relation,\n",
    "#to all other members of the same SCC. This produces intractable relation trees for each\n",
    "#of these 758 synsets, i. e. trees that are too big to compute or display on any computer.\n",
    "\n",
    "#For example, the synset ‘concrete.a.01’ is a member of the largest SCC,\n",
    "##so its also_sees() tree is intractable, and can normally only be handled by\n",
    "#limiting the “depth” parameter to display a small number of levels:\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(wn.synset('concrete.a.01').tree(lambda s:s.also_sees(),cut_mark='...',depth=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12301ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('bound.a.01'),\n",
      " [Synset('unfree.a.02'),\n",
      "  [Synset('confined.a.02'),\n",
      "   [Synset('restricted.a.01'), [Synset('classified.a.02')]]],\n",
      "  [Synset('dependent.a.01')]]]\n",
      "[Synset('bound.a.01'),\n",
      " [Synset('unfree.a.02'),\n",
      "  \"Cycle(Synset('bound.a.01'),-3,...)\",\n",
      "  [Synset('confined.a.02'),\n",
      "   [Synset('restricted.a.01'),\n",
      "    [Synset('classified.a.02')],\n",
      "    \"Cycle(Synset('confined.a.02'),-5,...)\",\n",
      "    \"Cycle(Synset('unfree.a.02'),-5,...)\"],\n",
      "   \"Cycle(Synset('unfree.a.02'),-4,...)\"],\n",
      "  [Synset('dependent.a.01'), \"Cycle(Synset('unfree.a.02'),-4,...)\"],\n",
      "  \"Cycle(Synset('restricted.a.01'),-3,...)\"]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8954/3529948945.py:16: UserWarning: Discarded redundant search for Synset('bound.a.01') at depth -3\n",
      "  pprint(wn.synset('bound.a.01').acyclic_tree(lambda s:s.also_sees()))\n",
      "/home/andrewcgaitskell/.local/share/virtualenvs/JokeIdeaGenerator-fEmoDMJg/lib/python3.8/site-packages/nltk/util.py:419: UserWarning: Discarded redundant search for Synset('confined.a.02') at depth -5\n",
      "  acyclic_depth_first(\n",
      "/home/andrewcgaitskell/.local/share/virtualenvs/JokeIdeaGenerator-fEmoDMJg/lib/python3.8/site-packages/nltk/util.py:419: UserWarning: Discarded redundant search for Synset('unfree.a.02') at depth -5\n",
      "  acyclic_depth_first(\n",
      "/home/andrewcgaitskell/.local/share/virtualenvs/JokeIdeaGenerator-fEmoDMJg/lib/python3.8/site-packages/nltk/util.py:419: UserWarning: Discarded redundant search for Synset('unfree.a.02') at depth -4\n",
      "  acyclic_depth_first(\n",
      "/tmp/ipykernel_8954/3529948945.py:16: UserWarning: Discarded redundant search for Synset('restricted.a.01') at depth -3\n",
      "  pprint(wn.synset('bound.a.01').acyclic_tree(lambda s:s.also_sees()))\n",
      "/tmp/ipykernel_8954/3529948945.py:21: UserWarning: Discarded redundant search for Synset('bound.a.01') at depth -3\n",
      "  pprint(wn.synset('bound.a.01').acyclic_tree(lambda s:s.also_sees(),cut_mark='...'))\n",
      "/tmp/ipykernel_8954/3529948945.py:21: UserWarning: Discarded redundant search for Synset('restricted.a.01') at depth -3\n",
      "  pprint(wn.synset('bound.a.01').acyclic_tree(lambda s:s.also_sees(),cut_mark='...'))\n"
     ]
    }
   ],
   "source": [
    "##2.1 First solution: acyclic_tree()\n",
    "\n",
    "##On the other hand, the new acyclic_tree() function is able to also handle the intractable cases.\n",
    "##The also_sees() acyclic tree of ‘concrete.a.01’ is several hundred lines long,\n",
    "##so here is a simpler example, concerning a much smaller SCC: counting only five members,\n",
    "##the SCC that includes ‘bound.a.01’ is tractable with the normal tree() function, as seen above.\n",
    "\n",
    "#But while tree() only prunes redundancy within local branches,\n",
    "##acyclic_tree prunes the tree globally, thus discarding any additional redundancy,\n",
    "##and produces a tree that includes all reachable nodes (i. e. a _spanning tree_).\n",
    "##This tree is _minimal_ because it includes the reachable nodes only once,\n",
    "##but it is not necessarily a _Minimum Spanning Tree_ (MST), because the Depth-first search\n",
    "##strategy does not guarantee that nodes are reached through the lowest number of links\n",
    "##(as Breadth-first search would).\n",
    "\n",
    "pprint(wn.synset('bound.a.01').acyclic_tree(lambda s:s.also_sees()))\n",
    "\n",
    "#Again, specifying the “cut_mark” parameter increases verbosity,\n",
    "#so that the cycles are mentioned in the output, together with the level where they occur:\n",
    "\n",
    "pprint(wn.synset('bound.a.01').acyclic_tree(lambda s:s.also_sees(),cut_mark='...'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59f5f57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('bound.a.01'),\n",
      " [Synset('unfree.a.02'),\n",
      "  [Synset('confined.a.02')],\n",
      "  [Synset('dependent.a.01')],\n",
      "  [Synset('restricted.a.01'), [Synset('classified.a.02')]]]]\n"
     ]
    }
   ],
   "source": [
    "#2.2 Better solution: mst()\n",
    "\n",
    "'''A Minimum Spanning Tree (MST) spans all the nodes of a relation subgraph once,\n",
    "while guaranteeing that each node is reached through the shortest path possible.\n",
    "In unweighted relation graphs like WordNet, a MST can be computed very efficiently\n",
    "in linear time, using Breadth-First Search (BFS). Like acyclic_tree(),\n",
    "the new “unweighted_minimum_spanning_tree()” function (imported in the Wordnet module as “mst”)\n",
    "handles intractable trees, such as the example discussed above:\n",
    "    “wn.synset(‘concrete.a.01’).mst(lambda s:s.also_sees())”.\n",
    "\n",
    "But, while the also_sees() acyclic_tree of ‘bound.a.01’ reaches ‘classified.a.02’ through four links, using depth-first search as seen above (bound.a.01 > unfree.a.02 > confined.a.02 > restricted.a.01 > classified.a.02), in the following MST, the path to ‘classified.a.02’ is the shortest possible, consisting only in three links (bound.a.01 > unfree.a.02 > restricted.a.01 > classified.a.02):\n",
    "'''\n",
    "\n",
    "pprint(wn.synset('bound.a.01').mst(lambda s:s.also_sees()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e553294c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (4239787265.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_8954/4239787265.py\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    return 0\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def _shortest_hypernym_paths(self, simulate_root):\n",
    "        if self._name == \"*ROOT*\":\n",
    "            return {self: 0}\n",
    "\n",
    "        queue = deque([(self, 0)])\n",
    "        path = {}\n",
    "\n",
    "        while queue:\n",
    "            s, depth = queue.popleft()\n",
    "            if s in path:\n",
    "                continue\n",
    "            path[s] = depth\n",
    "\n",
    "            depth += 1\n",
    "            queue.extend((hyp, depth) for hyp in s._hypernyms())\n",
    "            queue.extend((hyp, depth) for hyp in s._instance_hypernyms())\n",
    "\n",
    "        if simulate_root:\n",
    "            fake_synset = Synset(None)\n",
    "            fake_synset._name = \"*ROOT*\"\n",
    "            path[fake_synset] = max(path.values()) + 1\n",
    "\n",
    "        return path\n",
    "\n",
    "\n",
    "##def shortest_path_distance(self, other, simulate_root=False):\n",
    "\"\"\"\n",
    "Returns the distance of the shortest path linking the two synsets (if\n",
    "one exists). For each synset, all the ancestor nodes and their\n",
    "distances are recorded and compared. The ancestor node common to both\n",
    "synsets that can be reached with the minimum number of traversals is\n",
    "used. If no ancestor nodes are common, None is returned. If a node is\n",
    "compared with itself 0 is returned.\n",
    "\n",
    ":type other: Synset\n",
    ":param other: The Synset to which the shortest path will be found.\n",
    ":return: The number of edges in the shortest path connecting the two\n",
    "    nodes, or None if no path exists.\n",
    "\"\"\"\n",
    "\n",
    "if self == other:\n",
    "    return 0\n",
    "\n",
    "dist_dict1 = self._shortest_hypernym_paths(simulate_root)\n",
    "dist_dict2 = other._shortest_hypernym_paths(simulate_root)\n",
    "\n",
    "# For each ancestor synset common to both subject synsets, find the\n",
    "# connecting path length. Return the shortest of these.\n",
    "\n",
    "inf = float(\"inf\")\n",
    "path_distance = inf\n",
    "for synset, d1 in dist_dict1.items():\n",
    "    d2 = dist_dict2.get(synset, inf)\n",
    "    path_distance = min(path_distance, d1 + d2)\n",
    "\n",
    "return None if math.isinf(path_distance) else path_distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
